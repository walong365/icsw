# Copyright (C) 2001-2008,2012-2017 Andreas Lang-Nevyjel
#
# Send feedback to: <lang-nevyjel@init.at>
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License Version 3 as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
""" cluster-server, backup process """

import bz2
import datetime
import os
import stat
import subprocess
import time

from django.conf import settings

from initat.cluster.backbone import db_tools
from initat.cluster.backbone.management.commands import dumpdataslow
from initat.cluster_server.config import global_config
from initat.tools import logging_tools, process_tools, threading_tools


class BackupProcess(threading_tools.icswProcessObj):
    def process_init(self):
        global_config.close()
        self.__log_template = logging_tools.get_logger(
            global_config["LOG_NAME"],
            global_config["LOG_DESTINATION"],
            zmq=True,
            context=self.zmq_context
        )
        db_tools.close_connection()
        self.register_func("start_backup", self._start_backup)

    def log(self, what, log_level=logging_tools.LOG_LEVEL_OK):
        self.__log_template.log(log_level, what)

    def get_ignore_list(self, table_name=False):
        from django.apps import apps
        # from django.db.models import get_apps, get_models
        ignore_list = []
        for _config in apps.get_app_configs():
            for _model in _config.get_models():
                if hasattr(_model, "CSW_Meta"):
                    if not getattr(_model.CSW_Meta, "backup", True):
                        if table_name:
                            ignore_list.append(_model._meta.db_table)
                        else:
                            ignore_list.append(
                                "{}.{}".format(
                                    _model._meta.app_label,
                                    _model._meta.model_name
                                )
                            )
        return ignore_list

    def _start_backup(self, *args, **kwargs):
        self.log("starting backup")
        bu_dir = global_config["DATABASE_DUMP_DIR"]
        if not os.path.isdir(bu_dir):
            self.log("creating bu_dir {}".format(bu_dir))
            os.mkdir(bu_dir)
        # delete old files
        for entry in os.listdir(bu_dir):
            if entry.count(".") and entry.split(".")[-1] in ["zip", "bz2", "psql"]:
                f_name = os.path.join(bu_dir, entry)
                # _stat = os.stat(f_name)
                diff_dt = datetime.datetime.now() - datetime.datetime.fromtimestamp(os.stat(f_name)[stat.ST_CTIME])
                if diff_dt.days > global_config["DATABASE_KEEP_DAYS"]:
                    self.log("removing backup %s" % (f_name))
                    os.unlink(f_name)
        for bu_type, bu_call in [
            ("database", self._database_backup),
            ("normal", self._normal_backup),
        ]:
            self.log("--------- backup type {} -------------".format(bu_type))
            s_time = time.time()
            bu_call(bu_dir)
            e_time = time.time()
            self.log(
                "{} backup finished in {}".format(
                    bu_type,
                    logging_tools.get_diff_time_str(e_time - s_time)
                )
            )
        self._exit_process()

    def _normal_backup(self, bu_dir):
        # start 'normal' django backup
        bu_name = datetime.datetime.now().strftime("db_bu_django_%Y%m%d_%H:%M:%S")
        full_path = os.path.join(
            bu_dir,
            bu_name,
        )
        self.log("storing backup in {}".format(full_path))
        buf_com = dumpdataslow.Command()
        buf_com.stdout = open(full_path, "wb")
        # get argument parser
        _ap = buf_com.create_parser("dumpdataslow", buf_com)
        _args = [
            "-a",
            "--format",
            "xml",
            "--traceback",
        ] + sum(
            [
                ["-e", _ignore] for _ignore in self.get_ignore_list()
            ],
            []
        ) + [
            "auth",
            "contenttypes",
            "sessions",
            "sites",
            "admin",
            "backbone",
        ]
        opts = _ap.parse_args(_args)
        buf_com.handle(**vars(opts))
        buf_com.stdout.close()
        open(
            "{}.bz2".format(full_path),
            "wb"
        ).write(
            bz2.compress(
                open(full_path, "rb").read()
            )
        )
        os.unlink(full_path)

    def _database_backup(self, bu_dir):
        bu_name = datetime.datetime.now().strftime("db_bu_database_%Y%m%d_%H:%M:%S")
        full_path = os.path.join(
            bu_dir,
            bu_name,
        )
        _def_db = settings.DATABASES.get("default", None)
        if not _def_db:
            self.log("no default database found", logging_tools.LOG_LEVEL_ERROR)
        else:
            self.log("found default database, keys:")
            for _key in sorted(_def_db.keys()):
                self.log("    {}={}".format(_key, _def_db[_key]))
            _engine = _def_db.get("ENGINE", "unknown").split(".")[-1]
            # map old to new values
            _engine = {
                "postgresql_psycopg2": "postgresql"
            }.get(_engine, _engine)
            bu_dict = {
                "postgresql": {
                    "dump_bin": "pg_dump",
                    "cmdlines": [
                        "{DUMP} -c -f {FILENAME}.psql -F c -Z 4 -h {HOST} -U {USER} {NAME} -w {EXCLUDE}",
                        "{DUMP} -f {FILENAME}.schema.psql -F c -Z 4 -h {HOST} -U {USER} {NAME} --schema-only -w {SCHEMA_ONLY}",
                    ],
                    "pgpass": True
                }
            }
            if _engine in bu_dict:
                _bu_info = bu_dict[_engine]
                _bin = process_tools.find_file(_bu_info["dump_bin"])
                if not _bin:
                    self.log("cannot find dump binary {}".format(_bu_info["dump_bin"]), logging_tools.LOG_LEVEL_ERROR)
                else:
                    self.log("found dump binary {} in {}".format(_bu_info["dump_bin"], _bin))
                    for _line in _bu_info["cmdlines"]:
                        cmdline = _line.format(
                            DUMP=_bin,
                            FILENAME=full_path,
                            EXCLUDE=" ".join(
                                [
                                    "-T {}".format(_ignore) for _ignore in self.get_ignore_list(True)
                                    ]
                            ),
                            SCHEMA_ONLY=" ".join(
                                [
                                    "-t {}".format(_ignore) for _ignore in self.get_ignore_list(True)
                                ]
                            ),
                            **_def_db
                        )
                        start_time = time.time()
                        _pgpass = _bu_info.get("pgpass", False)
                        if _pgpass:
                            _pgpassfile = "/root/.pgpass"
                            if os.path.exists(_pgpassfile):
                                _passcontent = open(_pgpassfile, "r").read()
                            else:
                                _passcontent = None
                            open(_pgpassfile, "w").write("{HOST}:*:{NAME}:{USER}:{PASSWORD}\n".format(**_def_db))
                            os.chmod(_pgpassfile, 0o600)
                        try:
                            _output = subprocess.check_output(cmdline.split(), stderr=subprocess.PIPE)
                        except subprocess.CalledProcessError:
                            self.log(
                                "error calling {}: {}".format(
                                    cmdline,
                                    process_tools.get_except_info(),
                                ),
                                logging_tools.LOG_LEVEL_ERROR
                            )
                        else:
                            end_time = time.time()
                            self.log(
                                "successfully called {} in {}: {}".format(
                                    cmdline,
                                    logging_tools.get_diff_time_str(end_time - start_time),
                                    _output,
                                )
                            )
                        if _pgpass:
                            if _passcontent:
                                open(_pgpassfile, "w").write(_passcontent)
                                os.chmod(_pgpassfile, 0o600)
                            else:
                                os.unlink(_pgpassfile)
            else:
                self.log(
                    "unsupported engine '{}' for database backup".format(
                        _engine
                    ),
                    logging_tools.LOG_LEVEL_WARN
                )

    def loop_post(self):
        self.__log_template.close()
